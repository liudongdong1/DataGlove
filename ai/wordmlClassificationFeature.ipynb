{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T00:49:40.904825Z",
     "start_time": "2021-04-14T00:49:40.897342Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as mp\n",
    "import sklearn.model_selection as ms\n",
    "import sklearn.svm as svm\n",
    "import sklearn.tree as st\n",
    "import sklearn.datasets as sd  # sklearn提供的数据集\n",
    "import sklearn.utils as su  # 可以把数据集按照行进行打乱\n",
    "import sklearn.metrics as sm\n",
    "import sklearn.ensemble as se\n",
    "import joblib\n",
    "import os\n",
    "import random\n",
    "from dataReadFeature import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T00:48:47.832396Z",
     "start_time": "2021-04-14T00:48:47.745424Z"
    }
   },
   "outputs": [],
   "source": [
    "#加载数据\n",
    "databasefoler=r\"../../data/temp/picFlex\"\n",
    "classLabel=[\"word\",\"word_testData\",\"digit\",\"digit_testData\"]\n",
    "\n",
    "# 读取测试数据\n",
    "test_x,test_y = FlexSensorDataRead(basefolder=databasefoler,classtype=classLabel[1]).getDataLabel()\n",
    "# 读取训练数据\n",
    "train_data = TorchDataset(basefolder=databasefoler, classtype=classLabel[0])\n",
    "train_x,train_y=train_data.getAllData()\n",
    "\n",
    "#查看一组数据\n",
    "print(\"test_x\",test_x[0],\"test_y\",test_y[0])\n",
    "print(\"train_x\",train_x[0],\"label_y\",train_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printPredictionResult(test_y,pred_test_y):\n",
    "    '''\n",
    "    ;function: 模型执行结果参数显示\n",
    "    ;parameters:\n",
    "        test_y: 真实标签数据；\n",
    "        pred_test_y: 模型预测的y数据\n",
    "    '''\n",
    "    print(sm.accuracy_score(test_y, pred_test_y))  #https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\n",
    "    bg = sm.classification_report(test_y, pred_test_y) #y_true, y_pred,Build a text report showing the main classification metrics.\n",
    "    print('分类报告：', bg, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T00:49:51.037502Z",
     "start_time": "2021-04-14T00:49:50.113886Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T00:50:14.289831Z",
     "start_time": "2021-04-14T00:50:08.545079Z"
    }
   },
   "outputs": [],
   "source": [
    "#------------------SVM 分类模型--------------\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "\t{'kernel':['linear'],'C':[1,10,100,1000]},\n",
    "\t{'kernel':['poly'],'C':[1,10],'degree':[2,3]},\n",
    "\t{'kernel':['rbf'],'C':[1,10,100,1000],'gamma':[1,0.1, 0.01, 0.001]}]\n",
    "\n",
    "grid = GridSearchCV(svm.SVC(),param_grid,cv=5) #实例化一个GridSearchCV类\n",
    "grid.fit(train_x, train_y)\n",
    "print(\"The best parameters are %s with a score of %0.2f\" %(grid.best_params_, grid.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------SVM 分类模型--------------\n",
    "svm_model=svm.SVC(gamma='0.01',C=1)   #需要设置参数\n",
    "svm_model.fit(train_x, train_y)\n",
    "pred_test_y = svm_model.predict(test_x)\n",
    "#统计准确率\n",
    "printPredictionResult(test_y,pred_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T13:17:20.324099Z",
     "start_time": "2021-04-13T13:17:20.187233Z"
    }
   },
   "outputs": [],
   "source": [
    "#------------------k-近邻分类器--------------\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#调参数\n",
    "knn = KNeighborsClassifier()\n",
    "grid_param={'n_neighbors':10,'algorithm',['auto','ball_tree','brute']}\n",
    "grid=GridSearchCV(knn,grid_param,cv=5)\n",
    "grid.fit(train_x, train_y)\n",
    "print(\"The best parameters are %s with a score of %0.2f\" %(grid.best_params_, grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------k-近邻分类器--------------\n",
    "knn = KNeighborsClassifier()  #todo 需要根据上一步来设置模型参数\n",
    "knn.fit(train_x, train_y)\n",
    "pred_test_knn = knn.predict(test_x)\n",
    "print('knn:',format(sm.accuracy_score(test_y, pred_test_knn),'.4f'))\n",
    "print('recall:',format(sm.recall_score(test_y, pred_test_knn,average='macro'),'.4f'))\n",
    "print('F1:',format(sm.f1_score(test_y, pred_test_knn, average='macro'),'.4f'))\n",
    "#统计准确率\n",
    "printPredictionResult(test_y,pred_test_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------Logistic Regression Classifier--------------\n",
    "#调参数\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lg = LogisticRegression()\n",
    "grid_param={'penalty':['l1', 'l2', 'elasticnet', 'none'],'solver',['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],'C':np.logspace(1, 4, 20)}\n",
    "grid=GridSearchCV(lg,grid_param,cv=5)\n",
    "grid.fit(train_x, train_y)\n",
    "print(\"The best parameters are %s with a score of %0.2f\" %(grid.best_params_, grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T13:17:13.198262Z",
     "start_time": "2021-04-13T13:17:13.125313Z"
    }
   },
   "outputs": [],
   "source": [
    "#------------------Logistic Regression Classifier--------------\n",
    "lg = LogisticRegression(penalty='l2')  #todo 需要根据上一步来设置模型参数\n",
    "lg.fit(train_x, train_y)\n",
    "pred_test_lg = lg.predict(test_x)\n",
    "print('accuracylg:',format(sm.accuracy_score(test_y, pred_test_lg),'.4f'))\n",
    "printPredictionResult(test_y,pred_test_lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------Random Forest Classifier--------------\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RFC = RandomForestClassifier()\n",
    "\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"max_features\": randint(1, 11),\n",
    "              \"min_samples_split\": randint(2, 11),\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "rng = np.random.RandomState(0)\n",
    "grid = HalvingRandomSearchCV(estimator=RFC, param_distributions=param_dist,\n",
    "                            factor=2, random_state=rng)\n",
    "grid.fit(train_x, train_y)\n",
    "print(\"The best parameters are %s with a score of %0.2f\" %(grid.best_params_, grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T13:17:33.444190Z",
     "start_time": "2021-04-13T13:17:33.395787Z"
    }
   },
   "outputs": [],
   "source": [
    "#------------------Random Forest Classifier--------------\n",
    "RFC = RandomForestClassifier(n_estimators=8)   #todo 需要根据上一步来设置模型参数\n",
    "RFC.fit(train_x, train_y)\n",
    "pred_test_rfc = RFC.predict(test_x)\n",
    "printPredictionResult(test_y,pred_test_rfc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------DecisionTreeClassifier--------------\n",
    "from sklearn import tree\n",
    "param = [{'criterion':['gini'],'max_depth':[30,50,60,100],'min_samples_leaf':[2,3,5,10],'min_impurity_decrease':[0.1,0.2,0.5]},\n",
    "         {'criterion':['gini','entropy']},\n",
    "         {'max_depth': [30,60,100], 'min_impurity_decrease':[0.1,0.2,0.5]}]\n",
    "grid = GridSearchCV(tree.DecisionTreeClassifier(),param_grid=param,cv=6)\n",
    "grid.fit(train_x, train_y)\n",
    "print(\"The best parameters are %s with a score of %0.2f\" %(grid.best_params_, grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T13:17:35.884023Z",
     "start_time": "2021-04-13T13:17:35.858238Z"
    }
   },
   "outputs": [],
   "source": [
    "#------------------DecisionTreeClassifier--------------\n",
    "tre = tree.DecisionTreeClassifier()   #todo 需要根据上一步来设置模型参数\n",
    "tre.fit(train_x, train_y)\n",
    "pred_test_tre = tre.predict(test_x)\n",
    "printPredictionResult(test_y,pred_test_tre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T13:17:39.978073Z",
     "start_time": "2021-04-13T13:17:38.927704Z"
    }
   },
   "outputs": [],
   "source": [
    "#------------------MLPClassifier--------------\n",
    "from sklearn import neural_network\n",
    "mlp=neural_network.MLPClassifier(max_iter=1000)\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes':[(10, ), (20, ), (5, 5)],\n",
    "    'activation':['logistic', 'tanh', 'relu'],\n",
    "    'alpha':[0.001, 0.01, 0.1, 0.4, 1]\n",
    "}\n",
    "\n",
    "grid = model_selection.GridSearchCV(estimator=mlp,\n",
    "                                   param_grid=param_grid,\n",
    "                                   scoring='accuracy', # 打分\n",
    "                                   cv=gkf.split(X,y,groups), # cv 方法\n",
    "                                   return_train_score=True, # 默认不返回 train 的score\n",
    "                                   refit=True, # 默认为 True, 用最好的模型+全量数据再次训练，用 gscv.best_estimator_ 获取最好模型\n",
    "                                   n_jobs=-1)\n",
    "grid.fit(train_x, train_y)\n",
    "print(\"The best parameters are %s with a score of %0.2f\" %(grid.best_params_, grid.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------MLPClassifier--------------\n",
    "mlp=neural_network.MLPClassifier(max_iter=1000) #todo 需要根据上一步来设置模型参数\n",
    "mlp.fit(train_x, train_y)\n",
    "pred_y = mlp.predict(test_x)\n",
    "printPredictionResult(test_y,pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------XGBClassifier--------------\n",
    "from xgboost import XGBClassifier\n",
    "#分类器使用 xgboost\n",
    "clf1 = xgb.XGBClassifier()\n",
    " \n",
    "#设定网格搜索的xgboost参数搜索范围，值搜索XGBoost的主要6个参数\n",
    "param_dist = {\n",
    "        'n_estimators':range(80,200,4),\n",
    "        'max_depth':range(2,15,1),\n",
    "        'learning_rate':np.linspace(0.01,2,20),\n",
    "        'subsample':np.linspace(0.7,0.9,20),\n",
    "        'colsample_bytree':np.linspace(0.5,0.98,10),\n",
    "        'min_child_weight':range(1,9,1)\n",
    "        }\n",
    " \n",
    "#GridSearchCV参数说明，clf1设置训练的学习器\n",
    "#param_dist字典类型，放入参数搜索范围\n",
    "#scoring = 'neg_log_loss'，精度评价方式设定为“neg_log_loss“\n",
    "#n_iter=300，训练300次，数值越大，获得的参数精度越大，但是搜索时间越长\n",
    "#n_jobs = -1，使用所有的CPU进行训练，默认为1，使用1个CPU\n",
    "grid = GridSearchCV(clf1,param_dist,cv = 3,scoring = 'neg_log_loss',n_iter=300,n_jobs = -1)\n",
    "grid.fit(train_x, train_y)\n",
    "print(\"The best parameters are %s with a score of %0.2f\" %(grid.best_params_, grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T13:17:58.642803Z",
     "start_time": "2021-04-13T13:17:58.585838Z"
    }
   },
   "outputs": [],
   "source": [
    "#------------------XGBClassifier--------------\n",
    "mo = XGBClassifier()   #todo 需要根据上一步来设置模型参数\n",
    "mo.fit(train_x, train_y)\n",
    "pred_y = mo.predict(test_x)\n",
    "printPredictionResult(test_y,pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T13:18:37.505325Z",
     "start_time": "2021-04-13T13:18:37.253381Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "RF = RandomForestRegressor()\n",
    "#设置初始的参数空间\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200,stop = 2000,num = 10)]\n",
    "min_samples_split = [2,5,10]\n",
    "min_samples_leaf = [1,2,4]\n",
    "max_depth = [5,8,10]\n",
    "max_features = ['auto','sqrt']\n",
    "bootstrap = [True,False]\n",
    "#将参数整理为字典格式\n",
    "random_params_group = {'n_estimators':n_estimators,\n",
    "                      'min_samples_split':min_samples_split,\n",
    "                      'min_samples_leaf':min_samples_leaf,\n",
    "                      'max_depth':max_depth,\n",
    "                      'max_features':max_features,\n",
    "                      'bootstrap':bootstrap}\n",
    "#建立RandomizedSearchCV模型\n",
    "grid =RandomizedSearchCV(RF,param_distributions = random_params_group,n_iter = 100,scoring = 'neg_mean_squared_error',verbose = 2,n_jobs = -1,cv = 3,random_state = 0)\n",
    "#使用该模型训练数据\n",
    "grid.fit(train_x, train_y)\n",
    "print(\"The best parameters are %s with a score of %0.2f\" %(grid.best_params_, grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用网格搜索进行细化处理\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "\n",
    "param_grid = {'n_estimators':[1100,1200,1300],\n",
    "             'min_samples_split':[4,5,6,7],\n",
    "             'min_samples_leaf':[3,4,5],\n",
    "             'max_depth':[4,5,6,7]}\n",
    "randomForest = RandomForestRegressor()\n",
    "grid = GridSearchCV(randomForest,param_grid = param_grid,scoring = 'neg_mean_squared_error',cv = 3,n_jobs = -1)\n",
    "start_time = time.time()\n",
    "grid.fit(train_x, train_y)\n",
    "end_time = time.time()\n",
    "print('模型训练用时:{}'.format(end_time - start_time))\n",
    "print(\"The best parameters are %s with a score of %0.2f\" %(grid.best_params_, grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomForest = RandomForestRegressor() #todo 需要根据上一步来设置模型参数\n",
    "randomForest.fit(train_x, train_y)\n",
    "pred_y = mo.predict(test_x)\n",
    "printPredictionResult(test_y,pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T13:24:41.663844Z",
     "start_time": "2021-04-13T13:24:41.617909Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = svm.SVC(kernel='linear', C=0.58)\n",
    "model.fit(train_x, train_y)\n",
    "pred_test_y = model.predict(test_x)\n",
    "\n",
    "#保存模型\n",
    "file = r'../../modefiles/svm_no_yes.joblib'\n",
    "joblib.dump(model,file)\n",
    "# 读取模型\n",
    "svm_model = joblib.load(file)\n",
    "pred_test_y = svm_model.predict(test_x)\n",
    "#统计准确率\n",
    "print(sm.accuracy_score(test_y, pred_test_y))  #https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\n",
    "bg = sm.classification_report(test_y, pred_test_y) #y_true, y_pred,Build a text report showing the main classification metrics.\n",
    "print('分类报告：', bg, sep='\\n')\n",
    "# 列表左边的一列为分类的标签名；support列为每个标签的出现次数\n",
    "# avg / total行为各列的均值（support列为总和）\n",
    "# macro , weighted 介绍 https://www.cnblogs.com/laozhanghahaha/p/12499979.html\n",
    "#保存混淆矩阵\n",
    "#def confusion_matrix(pred_test_y):\n",
    "#     coonfusion_plot = [[0]*10 for i in range(10)]\n",
    "#     for i in range(10):\n",
    "#         for j in range(30):\n",
    "#             coonfusion_plot[i][pred_test_y[i*30+j]] += 1\n",
    "#     return coonfusion_plot\n",
    "\n",
    "# pred_test = confusion_matrix(pred_test_y)\n",
    "# f_confusion = r'../../modefiles/confusion_matrix_no_yes.txt'\n",
    "# with open(f_confusion, 'w') as fl3:\n",
    "#     fl3.write(str(pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 【6】 GBDT(Gradient Boosting Decision Tree) Classifier\n",
    "# # 梯度增强决策树分类器\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "GBDT = GradientBoostingClassifier()\n",
    "GBDT.fit(train_x, train_y)\n",
    "pred_test_GBDT = GBDT.predict(test_x)\n",
    "print('accuracyGBDT:',format(sm.accuracy_score(test_y, pred_test_GBDT),'.4f'))\n",
    "print('recall:',format(sm.recall_score(test_y, pred_test_GBDT,average='macro'),'.4f'))\n",
    "print('F1:',format(sm.f1_score(test_y, pred_test_GBDT, average='macro'),'.4f'))\n",
    "\n",
    "# # 伯努利贝叶斯分类器\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "Bernoulli = BernoulliNB()\n",
    "Bernoulli.fit(train_x, train_y)\n",
    "pred_test_BernoulliNB = Gaussian.predict(test_x)\n",
    "print('BernoulliNB:',format(sm.accuracy_score(test_y, pred_test_BernoulliNB),'.4f'))\n",
    "\n",
    "# # 多项式贝叶斯分类器\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "Multinomial = MultinomialNB()\n",
    "Multinomial.fit(train_x, train_y)\n",
    "pred_test_Multinomial = Multinomial.predict(test_x)\n",
    "print('MultinomialNB:',format(sm.accuracy_score(test_y, pred_test_Multinomial),'.4f'))\n",
    "\n",
    "# 【7】 GaussianNB\n",
    "# # 高斯贝叶斯分类器\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "Gaussian = GaussianNB()\n",
    "Gaussian.fit(train_x, train_y)\n",
    "pred_test_Gaussian = Gaussian.predict(test_x)\n",
    "print('accuracyGaussian:',format(sm.accuracy_score(test_y, pred_test_Gaussian),'.4f'))\n",
    "print('recall:',format(sm.recall_score(test_y, pred_test_Gaussian,average='macro'),'.4f'))\n",
    "print('F1:',format(sm.f1_score(test_y, pred_test_Gaussian, average='macro'),'.4f'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dataglove] *",
   "language": "python",
   "name": "conda-env-dataglove-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}